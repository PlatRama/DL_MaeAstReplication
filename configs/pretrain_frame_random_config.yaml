# ============================================================================
# Pretraining Config - FRAME-BASED (for Speech Tasks)
# ============================================================================
seed: 42

# Data
data:
  manifest_path: "data/manifests/pretrain/train.tsv"
  valid_manifest_path: "data/manifests/pretrain/test.tsv"

  sample_rate: 16000
  max_duration: 10.0
  min_duration: null

  # Feature extraction
  feature_type: "fbank"
  n_mels: 128

  # Normalization
  normalize: true

# Model - FRAME-BASED
model:
  # Input type
  input_type: "frame"  # Use frame-based tokenization

  # Frame tokenization (128×2)
  frame_size_time: 2
  # frame_size_freq is always n_mels (128)

  # Also need patch sizes for config compatibility
  patch_size_time: 24
  patch_size_freq: 24

  # Encoder
  encoder_embed_dim: 768
  encoder_depth: 6
  encoder_num_heads: 12
  encoder_ffn_dim: 3072

  # Decoder
  decoder_embed_dim: 768
  decoder_depth: 2
  decoder_num_heads: 12
  decoder_ffn_dim: 3072

  # Positional embeddings
  use_sinusoidal_pos: true

  # Dropout
  dropout: 0.1

  # Architecture
  layer_norm_first: true  # Pre-LayerNorm

# Masking - RANDOM for frame-based
masking:
  mask_ratio: 0.75
  mask_type: "random"  # Random masking for speech
  mask_batched: true
  chunk_size_range: [3, 5]

# Loss configuration
loss:
  reconstruction_weight: 10.0  # λ = 10 as in paper
  contrastive_weight: 1.0
  temperature: 0.07  # For InfoNCE

# Training
training:
  # Optimizer
  optimizer: "adamw"
  learning_rate: 0.0001
  weight_decay: 0.01
  betas: [ 0.9, 0.999 ]
  eps: 1e-8

  # Scheduler
  scheduler: "polynomial"
  total_steps: 30000
  warmup_steps: 1500
  end_lr: 0.0
  power: 1.0  # Linear decay

  save_every: 2000
  keep_last_n: 3

  # Training settings
  batch_size: 32
  gradient_accumulation_steps: 1
  max_grad_norm: 1.0  # Gradient clipping
  use_amp: true  # Mixed precision training

# Logging
logging:
  log_dir: "logs/pretrain_frame_random"
  checkpoint_dir: "checkpoints/pretrain_frame_random"
  use_tensorboard: true
  log_every: 100
  eval_every: 5000

# Hardware
hardware:
  num_workers: 4
  pin_memory: true
  device: "cuda"